{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Getting started with APIs in Python\n",
                "\n",
                "using the [client credentials flow](https://developer.spotify.com/documentation/general/guides/authorization-guide/) to interact with spotify and learn the ins and outs of working with third party APIs\n",
                "\n",
                "## Initial Setup:\n",
                "- import `requests` so we can hit up our endpoints\n",
                "- import our client's id and secret values that we were given when we created the app with spotify\n",
                "- define some additional content that we're going to be working with"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "source": [
                "import requests\n",
                "from secrets import client_id, client_secret\n",
                "\n",
                "track_id = '6y0igZArWVi6Iz0rj35c1Y'\n",
                "base_endpoint = 'http://api.spotify.com/v1/'\n",
                "auth_url = 'https://accounts.spotify.com/api/token'"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Getting Authorisation\n",
                "the first thing we need to do is acquire an access token from spotify using our client id and client secret. this takes the form of a post request to an authorisation URL and a json formatted payload. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "source": [
                "auth_response = requests.post(auth_url, {\n",
                "    'grant_type': 'client_credentials',\n",
                "    'client_id': client_id,\n",
                "    'client_secret': client_secret,\n",
                "})"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "now that we have a response from spotify we can convert the received data to json and access its KVPs, most importantly the access token that'll allow us to make further requests."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "source": [
                "auth_response_data = auth_response.json()\n",
                "access_token = auth_response_data['access_token']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The variable `auth_response_data` is a json object comprising the following information:\n",
                "\n",
                "```json\n",
                "{\n",
                "    'access_token': 'a big long string of numbers and letters',\n",
                "    'token_type': 'Bearer',\n",
                "    'expires_in': 3600\n",
                "}\n",
                "```\n",
                "having the data as a json object means we can access the KVP contents using `[]` indexing.\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Accessing Spotify Data\n",
                "\n",
                "Now that we have authorisation we can start formulating queries in order to acquire meaningful data. first, we need some header information. refer to the spotify documentation for how to format headers in order to make successful requests."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "source": [
                "headers = {\n",
                "    'Authorization':'Bearer {token}'.format(token=access_token)\n",
                "}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Outlining the header here means we don't need to muck about with formatting json inside our next get request. Think of the header as the password you need in order to access the system.\n",
                "\n",
                "Spotify's going to expect endpoint requests to follow a specific configuration. This example will allow us to request a track's [audio features](https://developer.spotify.com/console/get-audio-features-track/).\n",
                "\n",
                "The next request is sent using the GET verb, which uses the URL as a means to transfer information from us to Spotify. The previous request was sent using POST, meaning the credentials were carried in the message body itself and it therefore more secure. \n",
                "\n",
                "### Sidenote: HTTP Body Data\n",
                "\n",
                "HTTP Body Data is the data bytes transmitted in an HTTP transaction message immediately following the headers if there is any (in the case of HTTP/0.9 no headers are transmitted).\n",
                "\n",
                "Most HTTP requests are GET requests without bodies. However, simulating requests with bodies is important to properly stress the proxy code and to test various hooks working with such requests. Most HTTP requests with bodies use POST or PUT request method.\n",
                "\n",
                "**Message Body**\n",
                "\n",
                "The message body part is optional for an HTTP message but if it is available then it is used to carry the entity-body associated with the request or response. If entity body is associated then usually Content-Type and Content-Length headers lines specify the nature of the body associated.\n",
                "\n",
                "A message body is the one which carries actual HTTP request data (including form data and uploaded etc.) and HTTP response data from the server ( including files, images etc). Following is a simple content of a message body:\n",
                "\n",
                "```html\n",
                "<html>\n",
                "<body>\n",
                "<h1>Hello, World!</h1>\n",
                "</body>\n",
                "</html>\n",
                "```\n",
                "\n",
                "For more details to HTTP messages and bodies refer to [w3org link](http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "source": [
                "response = requests.get(\n",
                "    base_endpoint + 'audio-features/' + track_id, headers=headers\n",
                ")\n",
                "\n",
                "response_data = response.json()\n",
                "print(response_data)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'danceability': 0.54, 'energy': 0.59, 'key': 0, 'loudness': -4.359, 'mode': 1, 'speechiness': 0.0528, 'acousticness': 0.446, 'instrumentalness': 0, 'liveness': 0.14, 'valence': 0.267, 'tempo': 119.878, 'type': 'audio_features', 'id': '6y0igZArWVi6Iz0rj35c1Y', 'uri': 'spotify:track:6y0igZArWVi6Iz0rj35c1Y', 'track_href': 'https://api.spotify.com/v1/tracks/6y0igZArWVi6Iz0rj35c1Y', 'analysis_url': 'https://api.spotify.com/v1/audio-analysis/6y0igZArWVi6Iz0rj35c1Y', 'duration_ms': 234910, 'time_signature': 4}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "As before, we get back a load of json, this time it's a load of information relating to the track we fed the endpoint\n",
                "\n",
                "```json\n",
                "{\n",
                "  \"danceability\": 0.54,\n",
                "  \"energy\": 0.59,\n",
                "  \"key\": 0,\n",
                "  \"loudness\": -4.359,\n",
                "  \"mode\": 1,\n",
                "  \"speechiness\": 0.0528,\n",
                "  \"acousticness\": 0.446,\n",
                "  \"instrumentalness\": 0,\n",
                "  \"liveness\": 0.14,\n",
                "  \"valence\": 0.267,\n",
                "  \"tempo\": 119.878,\n",
                "  \"type\": \"audio_features\",\n",
                "  \"id\": \"6y0igZArWVi6Iz0rj35c1Y\",\n",
                "  \"uri\": \"spotify:track:6y0igZArWVi6Iz0rj35c1Y\",\n",
                "  \"track_href\": \"https://api.spotify.com/v1/tracks/6y0igZArWVi6Iz0rj35c1Y\",\n",
                "  \"analysis_url\": \"https://api.spotify.com/v1/audio-analysis/6y0igZArWVi6Iz0rj35c1Y\",\n",
                "  \"duration_ms\": 234910,\n",
                "  \"time_signature\": 4\n",
                "}\n",
                "```"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "the Spotify API docs give detailed explanations of the [meanings of each of these values](https://developer.spotify.com/documentation/web-api/reference/#endpoint-get-audio-features). Again, because this is all json formatted it's ripe for mucking about with, extracting the KVPs using index notation, e.g:"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "track_danceability = response_data['danceability']\n",
                "print(track_danceability)   # => 0.54"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Putting it all together\n",
                "Now that we have access to all this data we can do things like punt it all into a pandas dataframe and muck about with it. We can access Autechre's discography using a similar request to before, but we need to change our endpoint given we want a frame of albums. The song endpoint won't work in this case."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "source": [
                "artist_id = '6WH1V41LwGDGmlPUhSZLHO'\n",
                "\n",
                "artist_request = requests.get(base_endpoint + 'artists/' + artist_id + '/albums', headers=headers,\n",
                "                       params={'include-groups': 'album', 'limit': 50})\n",
                "artist_response = artist_request.json()\n",
                "# print(artist_response)\n",
                "    # trust me, it's a _lot_ of data\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "artist_response['items'][0]\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "for album in artist_response['items']:\n",
                "    print(album['name'], ' - ', album['release_date'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Cleaning things up\n",
                "\n",
                "Now that we have each of Autechre's albums we can use that list to pull all the tracks. Not only that, but we can use Pandas to store all this data in a DataFrame object and clean things up from there. \n",
                "\n",
                "The next code snippet scans through our list of albums and only adds those which aren't already in the list. Once that's done we can hit up the tracks endpoint and pull down the data for each track on the album we're currently processing. The flow here is:\n",
                "1. ascertain the album is unique then add it to the list of albums\n",
                "2. scan that album for all its tracks, grab the data for each track\n",
                "3. combine each track with its album data in a single json object (dictionary?)\n",
                "4. append the dictionary to the list of `data`"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "source": [
                "data = []       # will eventually end up as a dataframe\n",
                "albums = []     # a a collection of unique albums (this could habe been a set?)\n",
                "\n",
                "for album in artist_response['items']:\n",
                "    album_name = album['name'].upper()\n",
                "    \n",
                "    if album_name in albums:\n",
                "        continue\n",
                "    else:\n",
                "        albums.append(album_name)\n",
                "    \n",
                "    print(album_name)\n",
                "    \n",
                "    # hitting up the tracks endpoint and pulling down the track data for each album\n",
                "    request = requests.get(base_endpoint + 'albums/' + album['id'] + '/tracks', headers=headers)\n",
                "    tracks = request.json()['items']\n",
                "    \n",
                "    for track in tracks:\n",
                "        # grabbing the audio features from each track\n",
                "        f = requests.get(base_endpoint + 'audio-features/' + track['id'], headers=headers)\n",
                "        f = f.json()\n",
                "        \n",
                "        # combining track geatures with album info\n",
                "        f.update({\n",
                "            'track_name': track['name'],\n",
                "            'album_name': album_name,\n",
                "            'release_date': album['release_date'],\n",
                "            'album_id': album['id']\n",
                "        })\n",
                "        \n",
                "        data.append(f)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now that we've got `data`, our list of dictionaries, we can import pandas and cast it to a DataFrame object"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\n",
                "data = pd.DataFrame(data)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Having everything in a DataFrame makes it nice and easy to clean up given Pandas' toolset."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data['release_date'] = pd.to_datetime(data['release_date'])\n",
                "data = data.sort_values(by='release_date', ascending=[False])"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit ('exploring-spotify': conda)"
        },
        "interpreter": {
            "hash": "7c5eabd7bca6104cd66a3d89dfb52b01492c29b86fd7a6ffe37fd4511c0d24d4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}